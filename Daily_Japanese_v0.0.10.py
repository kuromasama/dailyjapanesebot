import google.generativeai as genai
import requests
import os
import json
import random
import re
from datetime import datetime, timedelta
import time
import math

# ================= ç’°å¢ƒè®Šæ•¸ =================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
TG_BOT_TOKEN = os.getenv("TG_BOT_TOKEN")
TG_CHAT_ID = os.getenv("TG_CHAT_ID")

# æª”æ¡ˆè¨­å®š
VOCAB_FILE = "vocab.json"
USER_DATA_FILE = "user_data.json"
MODEL_NAME = 'models/gemini-2.5-flash' 

# N2 è¡åˆºè¨­å®š (åŠå¹´ = 180å¤©)
SPRINT_DURATION_DAYS = 180
TARGET_DIFFICULTY = 4.0  # è¨­å®š 4.0 ç‚ºç©©æ‹¿ N2 (ç”šè‡³ N1 å…¥é–€) çš„æ¨™æº–
START_DIFFICULTY = 2.0   # N4 èµ·é»

# å®‰å…¨è¨­å®š
SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

# ================= æª”æ¡ˆå­˜å–å·¥å…· =================

def load_json(filename, default_content):
    if os.path.exists(filename):
        try:
            with open(filename, "r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, dict) and isinstance(default_content, dict):
                    for k, v in default_content.items():
                        if k not in data: data[k] = v
                return data
        except: return default_content
    return default_content

def save_json(filename, data):
    # æ“´å¤§æ­·å²ç´€éŒ„ä¿å­˜é‡ä»¥ä¾› AI è©•ä¼°ï¼Œä¿ç•™æœ€è¿‘ 100 ç­†
    if filename == USER_DATA_FILE and "translation_log" in data:
        if len(data["translation_log"]) > 100:
            data["translation_log"] = data["translation_log"][-100:]
            
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def send_telegram(message):
    if not TG_BOT_TOKEN: print(f"[æ¨¡æ“¬ç™¼é€] {message[:50]}..."); return
    if not message: return

    clean_msg = message.replace("**", "").replace("##", "").replace("__", "")
    clean_msg = re.sub(r'<br\s*/?>', '\n', clean_msg)
    
    try:
        requests.post(f"https://api.telegram.org/bot{TG_BOT_TOKEN}/sendMessage", json={
            "chat_id": TG_CHAT_ID, "text": clean_msg
        })
    except Exception as e: print(f"TG ç™¼é€å¤±æ•—: {e}")

def normalize_text(text):
    if not text: return ""
    return text.strip().replace("ã€€", " ").lower()

# ================= è¼”åŠ©åŠŸèƒ½ï¼šè¨ˆç®—è¡åˆºé€²åº¦ =================

def get_sprint_status(user_data):
    """è¨ˆç®—ç›®å‰æ˜¯å¦è½å¾Œæ–¼ N2 è¡åˆºè¨ˆç•«"""
    stats = user_data["stats"]
    if "sprint_start_date" not in stats:
        # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡é‹è¡Œæ–°ç‰ˆï¼Œåˆå§‹åŒ–é–‹å§‹æ—¥æœŸç‚ºä»Šå¤©
        stats["sprint_start_date"] = str(datetime.now().date())
        return 0, 0, "ğŸš€ è¡åˆºè¨ˆç•«ä»Šæ—¥å•Ÿå‹•ï¼ç›®æ¨™ï¼šåŠå¹´å…§æ”»å…‹ N2ï¼"

    start_date = datetime.strptime(stats["sprint_start_date"], "%Y-%m-%d").date()
    today = datetime.now().date()
    days_passed = (today - start_date).days
    
    if days_passed <= 0: days_passed = 1

    # è¨ˆç®—ã€Œä»Šå¤©ç†è«–ä¸Šè©²æœ‰çš„é›£åº¦ã€ (ç·šæ€§æˆé•·)
    # å…¬å¼ï¼šèµ·é» + (ç¶“éå¤©æ•¸ / ç¸½å¤©æ•¸) * (çµ‚é» - èµ·é»)
    progress_ratio = min(1.0, days_passed / SPRINT_DURATION_DAYS)
    expected_difficulty = START_DIFFICULTY + progress_ratio * (TARGET_DIFFICULTY - START_DIFFICULTY)
    
    current_difficulty = float(stats.get("current_difficulty", 2.0))
    
    diff = current_difficulty - expected_difficulty
    
    # è¨ˆç®—è½å¾Œæˆ–è¶…å‰å¤©æ•¸
    # æ¯æ—¥å¹³å‡æˆé•·ç‡
    daily_growth = (TARGET_DIFFICULTY - START_DIFFICULTY) / SPRINT_DURATION_DAYS
    days_diff = int(diff / daily_growth)

    status_msg = ""
    if days_diff >= 5:
        status_msg = f"ğŸ”¥ è¶…å‰é€²åº¦ï¼šä½ æ¯”é æœŸå¿«äº† {days_diff} å¤©ï¼å¤ªå¼·äº†ï¼"
    elif days_diff <= -5:
        status_msg = f"âš ï¸ è½å¾Œè­¦å ±ï¼šä½ è½å¾Œè¨ˆç•« {abs(days_diff)} å¤©äº†ï¼çš®ç¹ƒç·Šä¸€é»ï¼"
    else:
        status_msg = f"âœ… é€²åº¦æ­£å¸¸ï¼šç©©æ­¥é‚å‘ N2 ä¸­ã€‚"

    return days_passed, expected_difficulty, status_msg

# ================= AI æ ¸å¿ƒåŠŸèƒ½ =================

def assess_user_level(history_logs, specific_request=None):
    """
    [CH] åŠŸèƒ½ï¼šåˆ†ææ­·å²ç´€éŒ„ä¸¦é‡æ–°å®šç´š
    """
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel(MODEL_NAME)
    
    print("ğŸ§  AI æ­£åœ¨é€²è¡Œå…¨ç›¤èƒ½åŠ›è©•ä¼°...")

    # å¦‚æœä½¿ç”¨è€…æŒ‡å®šäº†ç­‰ç´š (ä¾‹å¦‚ [CH] N2)
    manual_level_map = {
        "n5": 1.0, "n4": 2.0, "n3": 3.0, "n2": 4.0, "n1": 5.0
    }
    
    if specific_request:
        req_lower = specific_request.lower().replace(" ", "")
        for key, val in manual_level_map.items():
            if key in req_lower:
                return val, f"æ”¶åˆ°æŒ‡ä»¤ï¼Œæ•™ç·´å·²å°‡é›£åº¦å¼·åˆ¶è¨­å®šç‚º {key.upper()} (Lv{val})ã€‚"
        
        # å˜—è©¦è§£æç´”æ•¸å­—
        match = re.search(r"(\d+(\.\d+)?)", specific_request)
        if match:
            val = float(match.group(1))
            return val, f"æ”¶åˆ°æŒ‡ä»¤ï¼Œé›£åº¦è¨­å®šç‚º Lv{val}ã€‚"

    # AI è‡ªå‹•è©•ä¼°
    history_text = "\n".join(history_logs[-50:]) # å–æœ€è¿‘ 50 ç­†
    
    prompt = f"""
    ä½ æ˜¯æ—¥æ–‡ N2 æ–¯å·´é”æ•™ç·´ã€‚ä½¿ç”¨è€…è¦æ±‚é‡æ–°è©•ä¼°å¥¹çš„æ—¥æ–‡ç­‰ç´šã€‚
    
    ã€ä½¿ç”¨è€…çš„æ­·å²ç¿»è­¯ç´€éŒ„ã€‘
    {history_text}
    
    è«‹æ ¹æ“šé€™äº›ç´€éŒ„ï¼Œå®¢è§€ä¸”åš´æ ¼åœ°åˆ¤æ–·å¥¹çš„æ—¥æ–‡ç¨‹åº¦ã€‚
    ç›®å‰çš„é›£åº¦é‡è¡¨å¦‚ä¸‹ï¼š
    - Lv 1.0: N5 (å–®å­—ç‚ºä¸»)
    - Lv 2.0: N4 (ç°¡å–®å¥å­)
    - Lv 3.0: N3 (æ—¥å¸¸æœƒè©±)
    - Lv 4.0: N2 (å•†æ¥­/æ–°èå…¥é–€)
    - Lv 5.0: N1 (é«˜éšç¶œåˆ)
    - Lv 6.0+: æ¯èªè€…/å°ˆæ¥­é ˜åŸŸ
    
    è«‹çµ¦å‡ºä¸€å€‹ **ç²¾ç¢ºçš„æµ®é»æ•¸ (ä¾‹å¦‚ 2.4 æˆ– 3.8)** ä»£è¡¨å¥¹ç›®å‰çš„å¯¦åŠ›ã€‚
    
    ã€è¼¸å‡ºæ ¼å¼ (JSON)ã€‘
    è«‹åªå›å‚³ JSONï¼Œä¸è¦æœ‰ markdown æ¨™è¨˜ï¼š
    {{
        "new_difficulty": 2.5,
        "reason": "ä½ çš„å–®å­—é‡ä¸éŒ¯ï¼Œä½†åŠ©è©é‚„æ˜¯å¸¸éŒ¯ï¼Œå»ºè­°å¾ N3 å‰åŠæ®µé–‹å§‹ç£¨ç·´ã€‚"
    }}
    """
    
    try:
        response = model.generate_content(prompt, safety_settings=SAFETY_SETTINGS)
        clean_text = response.text.replace("```json", "").replace("```", "").strip()
        result = json.loads(clean_text)
        return float(result["new_difficulty"]), result["reason"]
    except Exception as e:
        print(f"è©•ä¼°å¤±æ•—: {e}")
        return None, "ç„¡æ³•è©•ä¼°ï¼Œç¶­æŒåŸé›£åº¦ã€‚"

def ai_correction(user_text, translation_history, progress_status):
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel(MODEL_NAME)
    
    history_str = "\n".join(translation_history[-10:]) if translation_history else "(å°šç„¡æ­·å²ç´€éŒ„)"
    
    prompt = f"""
    ä½¿ç”¨è€…æ­£åœ¨ç·´ç¿’æ—¥æ–‡ï¼Œé€™æ˜¯å¥¹å‰›å‰›å‚³ä¾†çš„å…§å®¹ï¼š
    ã€Œ{user_text}ã€
    
    ã€æ­·å²ç´€éŒ„ã€‘
    {history_str}
    
    ã€ç•¶å‰ç­”é¡Œé€²åº¦ã€‘
    {progress_status}
    
    è«‹æ‰®æ¼”æ—¥æ–‡æ•™æˆèˆ‡æ–¯å·´é”æ•™ç·´ï¼Œå®Œæˆä»¥ä¸‹ä»»å‹™ï¼š
    1. **ğŸ“ˆ é€²åº¦è©•ä¼°**ï¼šæ¯”è¼ƒæ­·å²ç´€éŒ„ï¼Œåˆ¤æ–·æ˜¯å¦æœ‰é€²æ­¥ï¼Ÿçµ¦äºˆé¼“å‹µæˆ–è­¦æƒ•ã€‚
    2. **ğŸ¯ æ‰¹æ”¹**ï¼šè«‹é‡å°ä¸Šè¿°å…§å®¹é€²è¡Œæ‰¹æ”¹ï¼Œä¿®æ­£éŒ¯èª¤ (âœ…/âŒ)ã€‚
    3. **âœ¨ ä¸‰ç¨®å¤šæ¨£åŒ–è¡¨é”**ï¼šæä¾› æ­£å¼/å£èª/æ›å¥è©±èªª ä¸‰ç¨®ç‰ˆæœ¬ã€‚
    4. **ğŸ‘¹ æ–¯å·´é”å³æ™‚ç£ä¿ƒ**ï¼š
       - **æƒ…æ³ A (å¿…ä¿®)**ï¼šè‹¥é€²åº¦è½å¾Œï¼Œè«‹ç”¨ã€Œå¹½é»˜ä¸”å¸¶é»å˜²è«·ã€èªæ°£å‚¬ä¿ƒã€‚
       - **æƒ…æ³ B (Bonus)**ï¼šçµ¦äºˆé«˜åº¦è‚¯å®šï¼Œç¨±è®šé€™ä»½é¡å¤–çš„åŠªåŠ›ã€‚
    
    ã€æ ¼å¼è¦æ±‚ã€‘
    - å…¨ç¨‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚
    - ä½¿ç”¨ Emoji å€éš”ã€‚
    - ä¸ä½¿ç”¨ Markdown æ¨™é¡Œ (#)ã€‚
    """
    
    try:
        response = model.generate_content(prompt, safety_settings=SAFETY_SETTINGS)
        return response.text if response.text else "âš ï¸ AI æ‰¹æ”¹å¤±æ•—"
    except Exception as e:
        return f"âš ï¸ AI æ‰¹æ”¹éŒ¯èª¤: {e}"

# ================= é‚è¼¯æ ¸å¿ƒ =================

def process_data():
    print("ğŸ“¥ é–‹å§‹è™•ç†è³‡æ–™...")
    
    vocab_data = load_json(VOCAB_FILE, {"words": []})
    user_data = load_json(USER_DATA_FILE, {
        "stats": {
            "last_active": "2000-01-01", 
            "streak_days": 0,
            "execution_count": 0,
            "last_quiz_date": "2000-01-01",
            "last_quiz_questions_count": 0,
            "daily_answers_count": 0,
            "bonus_answers_count": 0,
            "yesterday_main_score": 0,
            "yesterday_bonus_score": 0,
            "last_update_id": 0,
            "current_difficulty": 1.0, # é è¨­å¾ N5 é–‹å§‹
            "sprint_start_date": str(datetime.now().date()) # è¡åˆºé–‹å§‹æ—¥
        },
        "pending_answers": "",
        "translation_log": []
    })
    
    stats = user_data["stats"]
    stats["current_difficulty"] = float(stats.get("current_difficulty", 1.0))

    # åˆå§‹åŒ–è£œå…¨
    for key in ["daily_answers_count", "bonus_answers_count", "yesterday_main_score", 
                "yesterday_bonus_score", "execution_count", "streak_days", "last_update_id"]:
        if key not in stats: stats[key] = 0

    url = f"https://api.telegram.org/bot{TG_BOT_TOKEN}/getUpdates"
    
    try:
        response = requests.get(url).json()
        if "result" not in response: return vocab_data, user_data
        
        is_updated = False
        updates_log = []
        correction_msgs = []
        
        today_str = str(datetime.now().date())
        today_answers_detected = 0
        pending_correction_texts = []
        
        last_processed_id = user_data["stats"]["last_update_id"]
        is_fresh_start = (last_processed_id == 0)
        max_id_in_this_run = last_processed_id

        for item in response["result"]:
            current_update_id = item["update_id"]
            if current_update_id <= last_processed_id: continue
            if current_update_id > max_id_in_this_run: max_id_in_this_run = current_update_id

            if str(item["message"]["chat"]["id"]) != str(TG_CHAT_ID): continue
            
            text = item["message"].get("text", "").strip()
            if not text: continue

            # === Case Special: [CH] æŒ‡ä»¤ ===
            if text.upper().startswith("[CH]"):
                if is_fresh_start: continue
                # æå–æŒ‡ä»¤åƒæ•¸ (ä¾‹å¦‚ [CH] N3)
                specific_req = text[4:].strip()
                new_diff, reason = assess_user_level(user_data["translation_log"], specific_req)
                
                if new_diff is not None:
                    user_data["stats"]["current_difficulty"] = new_diff
                    updates_log.append(f"ğŸ§  AI è©•ç´šå®Œæˆï¼šèª¿æ•´è‡³ Lv{new_diff}ã€‚\nğŸ’¬ ç†ç”±ï¼š{reason}")
                    is_updated = True
                else:
                    updates_log.append(f"âš ï¸ è©•ç´šå¤±æ•—ï¼š{reason}")
                continue

            # Case A: JSON
            if text.startswith("["):
                try:
                    imported = json.loads(text)
                    if isinstance(imported, list):
                        added = 0
                        for word in imported:
                            if "kanji" not in word: continue
                            kanji = word.get("kanji")
                            if not any(normalize_text(w["kanji"]) == normalize_text(kanji) for w in vocab_data["words"]):
                                vocab_data["words"].append({
                                    "kanji": kanji, "kana": word.get("kana", ""),
                                    "meaning": word.get("meaning", ""),
                                    "count": 1, "added_date": today_str
                                })
                                added += 1
                                is_updated = True
                        updates_log.append(f"ğŸ“‚ åŒ¯å…¥ {added} å€‹æ–°å–®å­—")
                except: pass
                continue

            # Case B: å­˜å–®å­—
            match = re.search(r"^([^/\s]+)(?:[ \u3000]+|/)([^/\s]+)(?:[ \u3000]+|/)(.+)$", text)
            if match:
                if is_fresh_start: continue
                kanji, kana, meaning = match.groups()
                if not kanji.lower().startswith("part") and len(text) < 50: 
                    found = False
                    for word in vocab_data["words"]:
                        if normalize_text(word["kanji"]) == normalize_text(kanji):
                            word["count"] += 1 
                            updates_log.append(f"ğŸ”„ å¼·åŒ–è¨˜æ†¶ï¼š{kanji}")
                            found = True
                            is_updated = True
                            break
                    if not found:
                        vocab_data["words"].append({
                            "kanji": kanji, "kana": kana, "meaning": meaning, 
                            "count": 1, "added_date": today_str
                        })
                        updates_log.append(f"âœ… æ”¶éŒ„ï¼š{kanji}")
                        is_updated = True
                    continue

            # Case C: ç¿»è­¯/ä½œæ¥­
            if not text.startswith("/"):
                if is_fresh_start: continue
                lines_count = len([l for l in text.split('\n') if len(l.strip()) > 1])
                lines_count = max(1, lines_count)
                today_answers_detected += lines_count
                
                pending_correction_texts.append(text)
                user_data["translation_log"].append(f"{today_str}: {text[:100]}") # å¢åŠ ç´€éŒ„é•·åº¦
                is_updated = True

        # === è¨ˆç®—è¨ˆåˆ† ===
        if today_answers_detected > 0:
            current_main = user_data["stats"]["daily_answers_count"]
            main_quota = 10 
            remaining_quota = max(0, main_quota - current_main)
            
            fill_main = min(today_answers_detected, remaining_quota)
            user_data["stats"]["daily_answers_count"] += fill_main
            
            spill_to_bonus = today_answers_detected - fill_main
            if spill_to_bonus > 0:
                user_data["stats"]["bonus_answers_count"] += spill_to_bonus
            is_updated = True

        # === æ‰¹æ”¹è™•ç† ===
        if not is_fresh_start and pending_correction_texts:
            combined_text = "\n\n".join(pending_correction_texts)
            history_context = user_data["translation_log"][:-len(pending_correction_texts)]
            
            main_count = user_data["stats"]["daily_answers_count"]
            bonus_count = user_data["stats"]["bonus_answers_count"]
            
            if bonus_count > 0:
                progress_str = f"ç‹€æ…‹ï¼šBonus æŒ‘æˆ°ä¸­ (å·²å®Œæˆ {bonus_count} é¡Œ Bonus)"
            else:
                progress_str = f"ç‹€æ…‹ï¼šæ¯æ—¥å¿…ä¿®é€²è¡Œä¸­ ({main_count}/10 é¡Œ)"

            result = ai_correction(combined_text, history_context, progress_str)
            title_text = f"ğŸ“ **ä½œæ¥­æ‰¹æ”¹ (å…± {len(pending_correction_texts)} å‰‡)ï¼š**"
            correction_msgs.append(f"{title_text}\n{result}")

        # æ›´æ–° update_id
        if max_id_in_this_run > user_data["stats"]["last_update_id"]:
            user_data["stats"]["last_update_id"] = max_id_in_this_run
            is_updated = True

        # Streak æ›´æ–°
        if user_data["stats"]["last_active"] != today_str:
            if today_answers_detected > 0 or is_updated:
                 yesterday = str((datetime.now() - timedelta(days=1)).date())
                 if user_data["stats"]["last_active"] == yesterday:
                     user_data["stats"]["streak_days"] += 1
                 else:
                     user_data["stats"]["streak_days"] = 1
                 user_data["stats"]["last_active"] = today_str
                 is_updated = True

        if updates_log: send_telegram("\n".join(set(updates_log)))
        for msg in correction_msgs:
            send_telegram(msg)
            time.sleep(1)

        return vocab_data, user_data

    except Exception as e:
        print(f"Error: {e}")
        return load_json(VOCAB_FILE, {}), load_json(USER_DATA_FILE, {})

# ================= æ¯æ—¥ç‰¹è¨“ç”Ÿæˆ (ç„¡é™é›£åº¦èˆ‡è¡åˆºç‰ˆ) =================

def get_difficulty_description(level_float):
    """
    å‹•æ…‹ç”Ÿæˆç„¡é™é›£åº¦çš„æè¿°
    """
    level_int = int(level_float)
    descriptions = {
        1: "Lv1 (æ–°æ‰‹)ï¼šN5 åŸºç¤ï¼Œå°ˆæ³¨æ–¼å–®å­—è¨˜æ†¶ã€‚",
        2: "Lv2 (åˆç´š)ï¼šN4 æ–‡æ³•ï¼Œç°¡å–®è¤‡åˆå¥ã€‚",
        3: "Lv3 (ä¸­ç´š)ï¼šN3 æ—¥å¸¸æ‡‰ç”¨ï¼Œæ¨™æº–å°è©±ã€‚",
        4: "Lv4 (é«˜ç´š)ï¼šN2 å•†æ¥­/æ–°èå…¥é–€ï¼Œé•·é›£å¥ã€‚",
        5: "Lv5 (é­”é¬¼)ï¼šN1 é«˜éšç¶œåˆï¼Œè€ƒé©—æ¥µé™ã€‚",
        6: "Lv6 (æ¯èªè€…)ï¼šå°ˆæ¥­é ˜åŸŸã€æŠ€è¡“æ–‡ä»¶ã€è‰±æ¾€èªå½™ã€‚",
        7: "Lv7 (æ–‡å­¸)ï¼šå¤æ–‡ã€å“²å­¸ã€è©©è©é¢¨æ ¼ã€‚",
        8: "Lv8 (ç¥)ï¼šAI èªç‚ºäººé¡ç„¡æ³•é”åˆ°çš„å¢ƒç•Œã€‚"
    }
    base_desc = descriptions.get(level_int, f"Lv{level_int} (è¶…è¶Šæ¥µé™)ï¼šæœªçŸ¥çš„é ˜åŸŸã€‚")
    next_desc = descriptions.get(level_int + 1, f"Lv{level_int+1} (æœªçŸ¥)")
    
    return base_desc, next_desc

def run_daily_quiz(vocab, user):
    if not vocab.get("words"):
        send_telegram("ğŸ“­ å–®å­—åº«ç©ºçš„ï¼è«‹å‚³é€å–®å­—æˆ–åŒ¯å…¥ JSONã€‚")
        return user
    
    pending_answers = user.get("pending_answers", "")
    if pending_answers:
        send_telegram(f"ğŸ—ï¸ **å‰æ¬¡æ¸¬é©—è©³è§£**\n\n{pending_answers}")
        time.sleep(3)
        user["pending_answers"] = ""
    
    today_str = str(datetime.now().date())
    is_new_day = (user["stats"]["last_quiz_date"] != today_str)

    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel(MODEL_NAME)
    
    weights = [w.get("count", 1) * 5 for w in vocab["words"]]
    k = min(10, len(vocab["words"]))
    selected_words = random.choices(vocab["words"], weights=weights, k=k)
    word_list = "\n".join([f"{w['kanji']} ({w['meaning']})" for w in selected_words])

    current_difficulty = float(user["stats"].get("current_difficulty", 1.0))
    
    # å–å¾—è¡åˆºç‹€æ…‹
    days_passed, expected_diff, sprint_msg = get_sprint_status(user)

    # ================= Scenario A: æ–°çš„ä¸€å¤© (æ¯æ—¥å¿…ä¿®) =================
    if is_new_day:
        user["stats"]["yesterday_main_score"] = user["stats"]["daily_answers_count"]
        user["stats"]["yesterday_bonus_score"] = user["stats"]["bonus_answers_count"]
        user["stats"]["daily_answers_count"] = 0
        user["stats"]["bonus_answers_count"] = 0
        
        user["stats"]["execution_count"] += 1
        exec_count = user["stats"]["execution_count"]
        streak_days = user["stats"]["streak_days"]
        
        main_score = user["stats"]["yesterday_main_score"]
        bonus_score = user["stats"]["yesterday_bonus_score"]
        
        emotion_prompt = ""
        difficulty_adjustment_msg = "" 

        # ç¬¬ä¸€æ¬¡é‹è¡Œ
        if user["stats"]["last_quiz_date"] == "2000-01-01":
            emotion_prompt = f"""
            é€™æ˜¯ä½ ç¬¬ä¸€æ¬¡èˆ‡ä½¿ç”¨è€…è¦‹é¢ã€‚
            è«‹ç†±æƒ…åœ°ä»‹ç´¹é€™æ˜¯ä¸€å€‹ç‚ºæœŸåŠå¹´çš„ **ã€ŒN2 è¡åˆºè¨ˆç•«ã€**ï¼
            ç›®å‰çš„é›£åº¦æ˜¯ Lv{current_difficulty}ï¼Œç›®æ¨™æ˜¯åŠå¹´å¾Œé”åˆ° Lv{TARGET_DIFFICULTY}ã€‚
            å‘Šè¨´å¥¹ï¼šåªè¦æ¯å¤©è·Ÿè‘—ç·´ï¼Œçµ•å°æ²’å•é¡Œï¼
            """
        else:
            # ğŸ¯ é›£åº¦å‹•æ…‹èª¿æ•´æ ¸å¿ƒ (ç„¡é™ç­‰ç´š)
            answer_rate = main_score / 10
            
            if answer_rate >= 0.8: # è¡¨ç¾å„ªç•°
                increase = 0.2 if answer_rate < 1.0 else 0.3
                # ç„¡ä¸Šé™ï¼Œå–æ¶ˆ min(5.0)
                current_difficulty += increase
                difficulty_adjustment_msg = f"ğŸ”¥ ç‹€æ…‹çµ•ä½³ï¼é›£åº¦å‡è‡³ Lv{current_difficulty:.1f}ï¼"
                
                # åˆ¤æ–·æ˜¯å¦å¯«äº† Bonus
                if bonus_score > 0:
                    emotion_prompt = f"æ˜¨æ—¥è¡¨ç¾ï¼šå¿…ä¿® {main_score}/10ï¼ŒBonus {bonus_score}ã€‚ç‹€æ…‹ï¼šç¥ä¸€èˆ¬çš„è‡ªå¾‹ï¼è«‹ç”¨æ¥µåº¦å´‡æ‹œèªæ°£èª‡çï¼ä¸¦æåˆ°ã€Œ{difficulty_adjustment_msg}ã€ã€‚"
                else:
                    emotion_prompt = f"æ˜¨æ—¥è¡¨ç¾ï¼šå¿…ä¿® {main_score}/10ã€‚ç‹€æ…‹ï¼šå„ªç§€ã€‚æåˆ°ã€Œ{difficulty_adjustment_msg}ã€ã€‚"

            elif answer_rate >= 0.4: # è¡¨ç¾æ™®é€š
                # åªæœ‰æ™®é€šï¼Œä½†å¦‚æœã€Œè½å¾Œé€²åº¦ã€ï¼Œé‚„æ˜¯è¦ç¨å¾®æ–½å£“
                if current_difficulty < expected_diff:
                    emotion_prompt = f"æ˜¨æ—¥è¡¨ç¾ï¼šæ™®é€šã€‚é›–ç„¶æ²’é™ç´šï¼Œä½†æˆ‘å€‘è½å¾Œé€²åº¦äº†ï¼è«‹ç¨å¾®åš´è‚…ä¸€é»æé†’å¥¹åŠ å¿«è…³æ­¥ã€‚"
                else:
                    emotion_prompt = f"æ˜¨æ—¥è¡¨ç¾ï¼šæ™®é€šã€‚ç¶­æŒç›®å‰é›£åº¦ Lv{current_difficulty:.1f}ã€‚"
                
            else: # è¡¨ç¾å·® (0~3é¡Œ)
                if current_difficulty > 1.0:
                    decrease = 0.3
                    current_difficulty = max(1.0, current_difficulty - decrease)
                    difficulty_adjustment_msg = f"ğŸ“‰ æ²’é—œä¿‚ï¼Œæˆ‘å€‘å…ˆé™åˆ° Lv{current_difficulty:.1f} æ‰¾å›æ‰‹æ„Ÿã€‚"
                else:
                    difficulty_adjustment_msg = "âš ï¸ å·²ç¶“æ˜¯æœ€ä½é›£åº¦ Lv1.0 äº†ï¼Œä¸èƒ½å†é€€äº†ï¼"
                
                emotion_prompt = f"""
                æ˜¨æ—¥è¡¨ç¾ï¼šå¿…ä¿® {main_score}/10ã€‚ç‹€æ…‹ï¼šå·æ‡¶ï¼
                è«‹é–‹å•Ÿã€å¹½é»˜æƒ…å‹’æ¨¡å¼ ğŸ˜ˆã€‘ã€‚
                ä¸¦æåˆ°ã€Œ{difficulty_adjustment_msg}ã€ã€‚
                ç‰¹åˆ¥æ³¨æ„ï¼šè«‹å¼•ç”¨ã€Œè¡åˆºç‹€æ…‹ã€ä¾†è­¦å‘Šå¥¹ (ä¾‹å¦‚ï¼šæˆ‘å€‘å·²ç¶“è½å¾Œ X å¤©äº†ï¼Œæ²’æ™‚é–“ç¡è¦ºäº†ï¼)ã€‚
                """
            
            user["stats"]["current_difficulty"] = float(f"{current_difficulty:.1f}")

        print(f"ğŸ¤– ç”Ÿæˆæ¯æ—¥å¿…ä¿® (10é¡Œ) - é›£åº¦: {current_difficulty:.1f}...")
        
        base_level = int(current_difficulty)
        next_level = base_level + 1
        decimal_part = current_difficulty - base_level
        base_desc, next_desc = get_difficulty_description(current_difficulty)
        
        prompt = f"""
        ä½ æ˜¯æ—¥æ–‡ N2 è¡åˆºç­æ•™ç·´ã€‚
        
        ã€è¡åˆºç‹€æ…‹ã€‘
        - ç›®å‰é€²åº¦: Day {days_passed} / {SPRINT_DURATION_DAYS}
        - ç‹€æ…‹è¨Šæ¯: {sprint_msg}
        
        **ğŸ¯ ç›®æ¨™é›£åº¦ç­‰ç´šï¼š{current_difficulty:.1f}**
        è«‹æ··åˆå‡ºé¡Œï¼š
        - **åŸºç¤ (Lv{base_level})**ï¼š{base_desc} (ä½” {(1-decimal_part)*100:.0f}%)
        - **é€²éš (Lv{next_level})**ï¼š{next_desc} (ä½” {decimal_part*100:.0f}%)
        
        ã€æƒ…ç·’èˆ‡é–‹å ´ã€‘
        {emotion_prompt}
        è«‹åœ¨é–‹å ´ç™½ä¸­å›å ±ä¸Šè¿°çš„ã€Œè¡åˆºç‹€æ…‹è¨Šæ¯ã€ã€‚
        
        ã€ä»Šæ—¥å–®å­—åº«ã€‘
        {word_list}
        
        è«‹è£½ä½œ **10 é¡Œ** ç¿»è­¯æ¸¬é©— (7é¡Œä¸­ç¿»æ—¥ï¼Œ3é¡Œæ—¥ç¿»ä¸­)ã€‚
        **é¡Œå‹è¦æ±‚ï¼šè«‹ç¶­æŒç°¡çŸ­ã€æ˜ç¢ºçš„å¥å­ã€‚åš´æ ¼éµå®ˆé›£åº¦æ¯”ä¾‹ã€‚**
        
        ã€è¼¸å‡ºæ ¼å¼è¦æ±‚ã€‘
        1. **èªè¨€**ï¼šé–‹å ´ç™½ã€èªªæ˜å…¨ç¹é«”ä¸­æ–‡ã€‚
        2. **æ’ç‰ˆ**ï¼šEmoji åˆ†éš”ï¼Œç„¡ Markdown æ¨™é¡Œï¼Œç„¡ HTMLã€‚
        3. **çµæ§‹**ï¼š
           - Part 1: é¡Œç›®å· (å«é–‹å ´ã€ç‹€æ…‹å›å ±ã€10é¡Œ)ã€‚**ä¸è¦**çµ¦ç­”æ¡ˆã€‚
           - åˆ†éš”ç·š: `|||SEPARATOR|||`
           - Part 2: è§£ç­”å· (å«åƒè€ƒç­”æ¡ˆèˆ‡è§£æ)ã€‚
        """
        
        try:
            response = model.generate_content(prompt, safety_settings=SAFETY_SETTINGS)
            if response.text and "|||SEPARATOR|||" in response.text:
                parts = response.text.split("|||SEPARATOR|||")
                send_telegram(parts[0].strip())
                user["pending_answers"] = parts[1].strip()
                
                user["stats"]["last_quiz_date"] = today_str
                user["stats"]["last_quiz_questions_count"] = 10
        except Exception as e:
            print(f"Error: {e}")
            send_telegram("âš ï¸ æ¸¬é©—ç”Ÿæˆå¤±æ•—")

    # ================= Scenario B: Bonus ç„¡é™æŒ‘æˆ° =================
    else:
        bonus_count = user["stats"]["bonus_answers_count"]
        base_diff = float(user["stats"].get("current_difficulty", 1.0))
        bonus_level_increase = (bonus_count // 3) * 0.5 + 0.5 
        bonus_difficulty = base_diff + bonus_level_increase # ç„¡ä¸Šé™
        
        print(f"ğŸ¤– ç”Ÿæˆ Bonus æŒ‘æˆ° - Lv{bonus_difficulty:.1f}...")
        
        base_level = int(bonus_difficulty)
        next_level = base_level + 1
        decimal_part = bonus_difficulty - base_level
        base_desc, next_desc = get_difficulty_description(bonus_difficulty)

        prompt = f"""
        ä½ æ˜¯æ—¥æ–‡ N2 æ–¯å·´é”æ•™ç·´ã€‚ä½¿ç”¨è€…ä¸»å‹•æŒ‘æˆ° Bonusã€‚
        
        è«‹ç”¨ã€Œå……æ»¿èª˜æƒ‘åŠ›èˆ‡æŒ‘æˆ°æ€§ã€çš„èªæ°£é–‹å ´ã€‚
        å‘Šè¨´å¥¹ï¼šæ—¢ç„¶ç‚ºäº† N2 é€™éº¼æ‹¼å‘½ï¼Œé‚£å°±ä¾†é»æ›´åˆºæ¿€çš„ï¼
        
        **ğŸ¯ Bonus é›£åº¦ç­‰ç´šï¼š{bonus_difficulty:.1f}**
        - Lv{base_level}: {base_desc}
        - Lv{next_level}: {next_desc}
        
        ä¸¦æä¾› **3 é¡Œ** ç¿»è­¯æŒ‘æˆ° (2ä¸­ç¿»æ—¥ï¼Œ1æ—¥ç¿»ä¸­)ã€‚
        
        ã€ä»Šæ—¥å–®å­—åº«ã€‘
        {word_list}
        
        ã€æ ¼å¼ã€‘
        - æ¨™é¡Œï¼šâš”ï¸ **Bonus ç„¡é™æŒ‘æˆ° (Lv{bonus_difficulty:.1f})** âš”ï¸
        - åˆ†éš”ç·š: `|||SEPARATOR|||`
        - å…¨ç¹é«”ä¸­æ–‡è§£èªªã€‚
        """

        try:
            response = model.generate_content(prompt, safety_settings=SAFETY_SETTINGS)
            if response.text and "|||SEPARATOR|||" in response.text:
                parts = response.text.split("|||SEPARATOR|||")
                send_telegram(parts[0].strip())
                user["pending_answers"] = parts[1].strip() 
                
        except Exception as e:
            print(f"Error: {e}")
            send_telegram("âš ï¸ Bonus ç”Ÿæˆå¤±æ•—")

    return user

if __name__ == "__main__":
    v_data, u_data = process_data()
    u_data_updated = run_daily_quiz(v_data, u_data)
    
    save_json(VOCAB_FILE, v_data)
    if u_data_updated:
        save_json(USER_DATA_FILE, u_data_updated)
    else:
        save_json(USER_DATA_FILE, u_data)