import google.generativeai as genai
import requests
import os
import json
import random
import re
from datetime import datetime, timedelta
import time

# ================= ç’°å¢ƒè®Šæ•¸ =================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
TG_BOT_TOKEN = os.getenv("TG_BOT_TOKEN")
TG_CHAT_ID = os.getenv("TG_CHAT_ID")

# æª”æ¡ˆè¨­å®š
VOCAB_FILE = "vocab.json"
USER_DATA_FILE = "user_data.json"
MODEL_NAME = 'models/gemini-2.5-flash' 

# å®‰å…¨è¨­å®š
SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

# ================= æª”æ¡ˆå­˜å–å·¥å…· =================

def load_json(filename, default_content):
    if os.path.exists(filename):
        try:
            with open(filename, "r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, dict) and isinstance(default_content, dict):
                    for k, v in default_content.items():
                        if k not in data: data[k] = v
                return data
        except: return default_content
    return default_content

def save_json(filename, data):
    if filename == USER_DATA_FILE and "translation_log" in data:
        if len(data["translation_log"]) > 30:
            data["translation_log"] = data["translation_log"][-30:]
            
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def send_telegram(message):
    if not TG_BOT_TOKEN: print(f"[æ¨¡æ“¬ç™¼é€] {message[:50]}..."); return
    if not message: return

    clean_msg = message.replace("**", "").replace("##", "").replace("__", "")
    clean_msg = re.sub(r'<br\s*/?>', '\n', clean_msg)
    
    try:
        requests.post(f"https://api.telegram.org/bot{TG_BOT_TOKEN}/sendMessage", json={
            "chat_id": TG_CHAT_ID, "text": clean_msg
        })
    except Exception as e: print(f"TG ç™¼é€å¤±æ•—: {e}")

def normalize_text(text):
    if not text: return ""
    return text.strip().replace("ã€€", " ").lower()

# ================= AI æ ¸å¿ƒ (Prompt å„ªåŒ–ç‰ˆ) =================

def ai_correction(user_text, translation_history, progress_status):
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel(MODEL_NAME)
    
    print(f"ğŸ¤– AI æ­£åœ¨æ‰¹æ”¹ (é€²åº¦ {progress_status})...")
    history_str = "\n".join(translation_history[-10:]) if translation_history else "(å°šç„¡æ­·å²ç´€éŒ„)"
    
    # ğŸ”¥ æ‰¹æ”¹ Promptï¼šå€åˆ†å¿…ä¿®èˆ‡ Bonus çš„æ…‹åº¦
    prompt = f"""
    ä½¿ç”¨è€…æ­£åœ¨ç·´ç¿’æ—¥æ–‡ï¼Œé€™æ˜¯å¥¹å‰›å‰›å‚³ä¾†çš„å…§å®¹ï¼š
    ã€Œ{user_text}ã€
    
    ã€æ­·å²ç´€éŒ„ã€‘
    {history_str}
    
    ã€ç•¶å‰ç­”é¡Œé€²åº¦ã€‘
    {progress_status}
    
    è«‹æ‰®æ¼”æ—¥æ–‡æ•™æˆèˆ‡æ–¯å·´é”æ•™ç·´ï¼Œå®Œæˆä»¥ä¸‹ä»»å‹™ï¼š
    1. **ğŸ“ˆ é€²åº¦è©•ä¼°**ï¼šæ¯”è¼ƒæ­·å²ç´€éŒ„ï¼Œåˆ¤æ–·æ˜¯å¦æœ‰é€²æ­¥ï¼Ÿçµ¦äºˆé¼“å‹µæˆ–è­¦æƒ•ã€‚
    2. **ğŸ¯ æ‰¹æ”¹**ï¼šè«‹é‡å°ä¸Šè¿°å…§å®¹é€²è¡Œæ‰¹æ”¹ï¼Œä¿®æ­£éŒ¯èª¤ (âœ…/âŒ)ã€‚
    3. **âœ¨ ä¸‰ç¨®å¤šæ¨£åŒ–è¡¨é”**ï¼šæä¾› æ­£å¼/å£èª/æ›å¥è©±èªª ä¸‰ç¨®ç‰ˆæœ¬ã€‚
    4. **ğŸ‘¹ æ–¯å·´é”å³æ™‚ç£ä¿ƒ (é‡è¦)**ï¼š
       - è«‹æŸ¥çœ‹ã€ç•¶å‰ç­”é¡Œé€²åº¦ã€‘ã€‚
       - **æƒ…æ³ Aï¼šé‚„åœ¨å¯«æ¯æ—¥å¿…ä¿® (10é¡Œæœªæ»¿)**ï¼š
         - å¦‚æœé€²åº¦åš´é‡è½å¾Œï¼Œè«‹åœ¨çµå°¾åŠ ä¸Šä¸€å¥**ã€Œå¹½é»˜ä¸”å¸¶é»å˜²è«·çš„å‚¬ä¿ƒã€** (ä¾‹å¦‚ï¼šã€Œæ‰å¯«ä¸€é¡Œï¼Ÿæ‰‹æŒ‡æŠ½ç­‹äº†å—ï¼Ÿå¿«é»æŠŠå‰©ä¸‹çš„äº¤å‡ºä¾†ï¼ã€)ã€‚
         - å¦‚æœå¿«å®Œæˆäº†ï¼Œçµ¦äºˆé¼“å‹µã€‚
       - **æƒ…æ³ Bï¼šæ­£åœ¨å¯« Bonus (å·²é€²å…¥ Bonus éšæ®µ)**ï¼š
         - **çµ•å°ç¦æ­¢ç½µäººæˆ–å‚¬ä¿ƒ**ã€‚
         - Bonus æ˜¯é¡å¤–çš„åŠªåŠ›ï¼Œç„¡è«–å¯«å¹¾é¡Œï¼Œéƒ½è«‹çµ¦äºˆé«˜åº¦è‚¯å®š (ä¾‹å¦‚ï¼šã€Œç«Ÿç„¶é‚„é¡˜æ„å¤šå¯«ï¼Œé€™ä»½ç†±æƒ…å°±æ˜¯åˆæ ¼çš„ä¿è­‰ï¼ã€)ã€‚
         - é‡é»æ”¾åœ¨ã€Œæ­£ç¢ºç‡ã€èˆ‡ã€Œå¥å‹é‹ç”¨ã€çš„è®šç¾ã€‚
    
    ã€æ ¼å¼åš´æ ¼è¦æ±‚ã€‘
    1. **èªè¨€**ï¼šè§£èªªèˆ‡è©•èªè«‹å…¨ç¨‹ä½¿ç”¨ã€Œç¹é«”ä¸­æ–‡ã€(Traditional Chinese)ã€‚
    2. **æ’ç‰ˆ**ï¼š
       - **åš´ç¦** ä½¿ç”¨ Markdown æ¨™é¡Œ (å¦‚ # æˆ– ##)ã€‚
       - è«‹ä½¿ç”¨ Emoji (å¦‚ ğŸ“ˆ, ğŸ¯, âœ¨, ğŸ‘¹, ğŸ‘”, ğŸ», ğŸ”„) ä¾†å€éš”ã€‚
       - **åš´ç¦** ä½¿ç”¨ HTML æ¨™ç±¤ (å¦‚ <br>)ï¼Œè«‹ç›´æ¥æ›è¡Œã€‚
    """
    
    try:
        response = model.generate_content(prompt, safety_settings=SAFETY_SETTINGS)
        return response.text if response.text else "âš ï¸ AI æ‰¹æ”¹å¤±æ•—"
    except Exception as e:
        return f"âš ï¸ AI æ‰¹æ”¹éŒ¯èª¤: {e}"

# ================= é‚è¼¯æ ¸å¿ƒ =================

def process_data():
    print("ğŸ“¥ é–‹å§‹è™•ç†è³‡æ–™...")
    
    vocab_data = load_json(VOCAB_FILE, {"words": []})
    user_data = load_json(USER_DATA_FILE, {
        "stats": {
            "last_active": "2000-01-01", 
            "streak_days": 0,
            "execution_count": 0,
            "last_quiz_date": "2000-01-01",
            "last_quiz_questions_count": 0,
            "daily_answers_count": 0,
            "bonus_answers_count": 0,
            "yesterday_main_score": 0,
            "yesterday_bonus_score": 0,
            "last_update_id": 0,
            "current_difficulty": 2.0  # æ”¹ç‚ºæµ®é»æ•¸é è¨­å€¼
        },
        "pending_answers": "",
        "translation_log": []
    })
    
    stats = user_data["stats"]
    if "current_difficulty" not in stats: stats["current_difficulty"] = 2.0
    # ç¢ºä¿èˆŠè³‡æ–™çš„ int æœƒè¢«è½‰ç‚º float
    stats["current_difficulty"] = float(stats["current_difficulty"])

    for key in ["daily_answers_count", "bonus_answers_count", "yesterday_main_score", 
                "yesterday_bonus_score", "execution_count", "streak_days", "last_update_id"]:
        if key not in stats: stats[key] = 0

    url = f"https://api.telegram.org/bot{TG_BOT_TOKEN}/getUpdates"
    
    try:
        response = requests.get(url).json()
        if "result" not in response: return vocab_data, user_data
        
        is_updated = False
        updates_log = []
        correction_msgs = []
        
        today_str = str(datetime.now().date())
        today_answers_detected = 0
        
        pending_correction_texts = []
        
        last_processed_id = user_data["stats"]["last_update_id"]
        is_fresh_start = (last_processed_id == 0)
        max_id_in_this_run = last_processed_id

        for item in response["result"]:
            current_update_id = item["update_id"]
            if current_update_id <= last_processed_id: continue
            if current_update_id > max_id_in_this_run: max_id_in_this_run = current_update_id

            if str(item["message"]["chat"]["id"]) != str(TG_CHAT_ID): continue
            
            msg_time = datetime.fromtimestamp(item["message"]["date"])
            if datetime.now() - msg_time > timedelta(hours=24): continue
            
            text = item["message"].get("text", "").strip()
            if not text: continue

            # Case A: JSON
            if text.startswith("["):
                try:
                    imported = json.loads(text)
                    if isinstance(imported, list):
                        added = 0
                        for word in imported:
                            if "kanji" not in word: continue
                            kanji = word.get("kanji")
                            if not any(normalize_text(w["kanji"]) == normalize_text(kanji) for w in vocab_data["words"]):
                                vocab_data["words"].append({
                                    "kanji": kanji, "kana": word.get("kana", ""),
                                    "meaning": word.get("meaning", ""),
                                    "count": 1, "added_date": today_str
                                })
                                added += 1
                                is_updated = True
                        updates_log.append(f"ğŸ“‚ åŒ¯å…¥ {added} å€‹æ–°å–®å­—")
                except: pass
                continue

            # Case B: å­˜å–®å­—
            match = re.search(r"^([^/\s]+)(?:[ \u3000]+|/)([^/\s]+)(?:[ \u3000]+|/)(.+)$", text)
            if match:
                if is_fresh_start: continue
                kanji, kana, meaning = match.groups()
                if not kanji.lower().startswith("part") and len(text) < 50: 
                    found = False
                    for word in vocab_data["words"]:
                        if normalize_text(word["kanji"]) == normalize_text(kanji):
                            word["count"] += 1 
                            updates_log.append(f"ğŸ”„ å¼·åŒ–è¨˜æ†¶ï¼š{kanji}")
                            found = True
                            is_updated = True
                            break
                    if not found:
                        vocab_data["words"].append({
                            "kanji": kanji, "kana": kana, "meaning": meaning, 
                            "count": 1, "added_date": today_str
                        })
                        updates_log.append(f"âœ… æ”¶éŒ„ï¼š{kanji}")
                        is_updated = True
                    continue

            # Case C: ç¿»è­¯/ä½œæ¥­
            if not text.startswith("/"):
                if is_fresh_start: continue
                lines_count = len([l for l in text.split('\n') if len(l.strip()) > 1])
                lines_count = max(1, lines_count)
                today_answers_detected += lines_count
                
                pending_correction_texts.append(text)
                user_data["translation_log"].append(f"{today_str}: {text[:50]}")
                is_updated = True

        # === è¨ˆç®—è¨ˆåˆ† ===
        if today_answers_detected > 0:
            current_main = user_data["stats"]["daily_answers_count"]
            main_quota = 10 
            remaining_quota = max(0, main_quota - current_main)
            
            fill_main = min(today_answers_detected, remaining_quota)
            user_data["stats"]["daily_answers_count"] += fill_main
            
            spill_to_bonus = today_answers_detected - fill_main
            if spill_to_bonus > 0:
                user_data["stats"]["bonus_answers_count"] += spill_to_bonus
            is_updated = True

        # === æ‰¹æ”¹è™•ç† (å‚³éé€²åº¦ç‹€æ…‹) ===
        if not is_fresh_start and pending_correction_texts:
            combined_text = "\n\n".join(pending_correction_texts)
            history_context = user_data["translation_log"][:-len(pending_correction_texts)]
            
            main_count = user_data["stats"]["daily_answers_count"]
            bonus_count = user_data["stats"]["bonus_answers_count"]
            
            # åˆ¤æ–·ç›®å‰æ˜¯åœ¨å¯«å¿…ä¿®é‚„æ˜¯ Bonus
            if bonus_count > 0:
                progress_str = f"ç‹€æ…‹ï¼šBonus æŒ‘æˆ°ä¸­ (å·²å®Œæˆ {bonus_count} é¡Œ Bonus)"
            else:
                progress_str = f"ç‹€æ…‹ï¼šæ¯æ—¥å¿…ä¿®é€²è¡Œä¸­ ({main_count}/10 é¡Œ)"

            result = ai_correction(combined_text, history_context, progress_str)
            
            title_text = f"ğŸ“ **ä½œæ¥­/ç·´ç¿’æ‰¹æ”¹ (å…± {len(pending_correction_texts)} å‰‡åˆä½µ)ï¼š**" if len(pending_correction_texts) > 1 else "ğŸ“ **ä½œæ¥­/ç·´ç¿’æ‰¹æ”¹ï¼š**"
            correction_msgs.append(f"{title_text}\n{result}")

        # æ›´æ–° update_id
        if max_id_in_this_run > user_data["stats"]["last_update_id"]:
            user_data["stats"]["last_update_id"] = max_id_in_this_run
            is_updated = True

        # Streak æ›´æ–°
        if user_data["stats"]["last_active"] != today_str:
            if today_answers_detected > 0 or is_updated:
                 yesterday = str((datetime.now() - timedelta(days=1)).date())
                 if user_data["stats"]["last_active"] == yesterday:
                     user_data["stats"]["streak_days"] += 1
                 else:
                     user_data["stats"]["streak_days"] = 1
                 user_data["stats"]["last_active"] = today_str
                 is_updated = True

        if updates_log: send_telegram("\n".join(set(updates_log)))
        for msg in correction_msgs:
            send_telegram(msg)
            time.sleep(1)

        return vocab_data, user_data

    except Exception as e:
        print(f"Error: {e}")
        return load_json(VOCAB_FILE, {}), load_json(USER_DATA_FILE, {})

# ================= æ¯æ—¥ç‰¹è¨“ç”Ÿæˆ =================

def run_daily_quiz(vocab, user):
    if not vocab.get("words"):
        send_telegram("ğŸ“­ å–®å­—åº«ç©ºçš„ï¼è«‹å‚³é€å–®å­—æˆ–åŒ¯å…¥ JSONã€‚")
        return user
    
    pending_answers = user.get("pending_answers", "")
    if pending_answers:
        send_telegram(f"ğŸ—ï¸ **å‰æ¬¡æ¸¬é©—è©³è§£**\n\n{pending_answers}")
        time.sleep(3)
        user["pending_answers"] = ""
    
    today_str = str(datetime.now().date())
    is_new_day = (user["stats"]["last_quiz_date"] != today_str)

    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel(MODEL_NAME)
    
    weights = [w.get("count", 1) * 5 for w in vocab["words"]]
    k = min(10, len(vocab["words"]))
    selected_words = random.choices(vocab["words"], weights=weights, k=k)
    word_list = "\n".join([f"{w['kanji']} ({w['meaning']})" for w in selected_words])

    # ç¢ºä¿æ˜¯æµ®é»æ•¸
    current_difficulty = float(user["stats"].get("current_difficulty", 2.0))
    
    # å®šç¾©æ¯å€‹æ•´æ•¸å±¤ç´šçš„åŸºæº–
    difficulty_levels = {
        1: "Lv1 (æ–°æ‰‹)ï¼šçŸ­å¥ï¼Œç„¡è¤‡åˆå¥ï¼Œå°ˆæ³¨æ–¼å–®å­—è¨˜æ†¶ã€‚",
        2: "Lv2 (åˆç´š)ï¼šç°¡å–®è¤‡åˆå¥ï¼ŒN3/N4 æ–‡æ³•ã€‚",
        3: "Lv3 (ä¸­ç´š)ï¼šæ¨™æº– N2 æ–‡æ³•ï¼Œå¥å­é•·åº¦é©ä¸­ã€‚",
        4: "Lv4 (é«˜ç´š)ï¼šåŒ…å«æ˜“æ··æ·†æ–‡æ³•ï¼Œè¼ƒé•·çš„é•·é›£å¥ã€‚",
        5: "Lv5 (é­”é¬¼)ï¼šæ–°èæ—¥æ–‡é¢¨æ ¼ï¼Œè¤‡é›œçµæ§‹ï¼Œè€ƒé©—æ¥µé™ã€‚"
    }

    # ================= Scenario A: æ–°çš„ä¸€å¤© (æ¯æ—¥å¿…ä¿®) =================
    if is_new_day:
        user["stats"]["yesterday_main_score"] = user["stats"]["daily_answers_count"]
        user["stats"]["yesterday_bonus_score"] = user["stats"]["bonus_answers_count"]
        user["stats"]["daily_answers_count"] = 0
        user["stats"]["bonus_answers_count"] = 0
        
        user["stats"]["execution_count"] += 1
        exec_count = user["stats"]["execution_count"]
        streak_days = user["stats"]["streak_days"]
        
        is_first_run = (user["stats"]["last_quiz_date"] == "2000-01-01") or (exec_count == 1)
        main_score = user["stats"]["yesterday_main_score"]
        bonus_score = user["stats"]["yesterday_bonus_score"]
        
        emotion_prompt = ""
        difficulty_adjustment_msg = "" 

        if is_first_run:
            emotion_prompt = """
            é€™æ˜¯ä½ ç¬¬ä¸€æ¬¡èˆ‡ä½¿ç”¨è€…è¦‹é¢ (Day 1)ã€‚
            **è«‹æ³¨æ„ï¼šè«‹å…¨ç¨‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ (Traditional Chinese)ã€‚**
            è«‹ç”¨å……æ»¿æ´»åŠ›ã€å°ˆæ¥­ä¸”æœŸå¾…çš„èªæ°£æ‰“æ‹›å‘¼ã€‚
            è‡ªæˆ‘ä»‹ç´¹ä½ æ˜¯ã€ŒN2 æ–¯å·´é” AI æ•™ç·´ã€ï¼Œä¸¦èªªæ˜æœªä¾†çš„è¨“ç·´æ¨¡å¼ï¼š
            ã€Œæ¯å¤©ä¸­åˆæˆ‘æœƒå‡ºé¡Œï¼Œéš”å¤©ä¸­åˆæˆ‘æœƒæª¢è¨æ˜¨å¤©çš„ä½œæ¥­ä¸¦å‡ºæ–°é¡Œç›®ã€‚ã€
            è«‹çµ¦äºˆä½¿ç”¨è€…æ»¿æ»¿çš„ä¿¡å¿ƒï¼
            """
            current_difficulty = 2.0
            
        else:
            # ğŸ¯ é›£åº¦å‹•æ…‹èª¿æ•´æ ¸å¿ƒ (å¹³æ»‘åŒ–)
            answer_rate = main_score / 10
            
            # 1. èª¿æ•´é‚è¼¯
            if answer_rate >= 0.8: # è¡¨ç¾å„ªç•°
                if current_difficulty < 5.0:
                    increase = 0.2 if answer_rate < 1.0 else 0.3 # æ»¿åˆ†åŠ å¤šä¸€é»ï¼Œå¦å‰‡å¾®èª¿
                    current_difficulty = min(5.0, current_difficulty + increase)
                    difficulty_adjustment_msg = f"ğŸ”¥ ç‹€æ…‹çµ•ä½³ï¼é›£åº¦å¾®å‡è‡³ Lv{current_difficulty:.1f}ï¼Œåˆ¥è®“æˆ‘å¤±æœ›ï¼"
                else:
                    difficulty_adjustment_msg = "ğŸ‘‘ ä½ å·²ç¶“é”åˆ°æœ€é«˜é›£åº¦ Lv5.0ï¼Œè«‹ä¿æŒé€™ä»½å¼·å¤§ï¼"
                
                if bonus_score > 0:
                    emotion_prompt = f"æ˜¨æ—¥è¡¨ç¾ï¼šå¿…ä¿® {main_score}/10ï¼ŒBonus {bonus_score}ã€‚ç‹€æ…‹ï¼šç¥ä¸€èˆ¬çš„è‡ªå¾‹ï¼è«‹ç”¨æ¥µåº¦å´‡æ‹œèªæ°£èª‡çï¼ä¸¦æåˆ°ã€Œ{difficulty_adjustment_msg}ã€ã€‚"
                else:
                    emotion_prompt = f"æ˜¨æ—¥è¡¨ç¾ï¼šå¿…ä¿® {main_score}/10ã€‚ç‹€æ…‹ï¼šå„ªç§€ã€‚çµ¦äºˆé«˜åº¦è‚¯å®šã€‚ä¸¦æåˆ°ã€Œ{difficulty_adjustment_msg}ã€ã€‚"

            elif answer_rate >= 0.4: # è¡¨ç¾æ™®é€š (ç¶­æŒæˆ–å¾®èª¿)
                # ç¨å¾®åŠ ä¸€é»é»å£“åŠ›ï¼Œæˆ–ä¿æŒä¸è®Š
                emotion_prompt = f"æ˜¨æ—¥è¡¨ç¾ï¼šå¿…ä¿® {main_score}/10ã€‚ç‹€æ…‹ï¼šå°šå¯ã€‚ç¶­æŒç›®å‰é›£åº¦ Lv{current_difficulty:.1f}ï¼Œæé†’è¦æ›´åŠªåŠ›ã€‚"
                
            else: # è¡¨ç¾å·® (0~3é¡Œ)
                if current_difficulty > 1.0:
                    decrease = 0.3 # é™å¹…ç¨å¾®æ˜é¡¯ä¸€é»ä»¥å…æŒ«æŠ˜
                    current_difficulty = max(1.0, current_difficulty - decrease)
                    difficulty_adjustment_msg = f"ğŸ“‰ çœ‹ä¾†ä½ ç´¯äº†ï¼Œæˆ‘å€‘å…ˆé™åˆ° Lv{current_difficulty:.1f}ï¼Œæ‰¾å›æ‰‹æ„Ÿå§ã€‚"
                else:
                    difficulty_adjustment_msg = "âš ï¸ å·²ç¶“æ˜¯æœ€ä½é›£åº¦ Lv1.0 äº†ï¼Œä¸èƒ½å†é€€äº†ï¼åŠ æ²¹å•Šï¼"
                
                emotion_prompt = f"""
                æ˜¨æ—¥è¡¨ç¾ï¼šå¿…ä¿® {main_score}/10ã€‚ç‹€æ…‹ï¼šå·æ‡¶ï¼
                è«‹é–‹å•Ÿã€å¹½é»˜æƒ…å‹’æ¨¡å¼ ğŸ˜ˆã€‘ã€‚
                ç”¨æœ‰é»å—å‚·ä½†åˆå¥½ç¬‘çš„èªæ°£ï¼Œè³ªå•å¥¹æ˜¯ä¸æ˜¯è¢«è¢«çª©ç¶æ¶äº†ï¼Ÿ
                ä¸¦æåˆ°ã€Œ{difficulty_adjustment_msg}ã€ã€‚
                **è«‹å…¨ç¨‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚**
                """
            
            user["stats"]["current_difficulty"] = float(f"{current_difficulty:.1f}")

        print(f"ğŸ¤– ç”Ÿæˆæ¯æ—¥å¿…ä¿® (10é¡Œ) - é›£åº¦: {current_difficulty:.1f}...")
        
        # è¨ˆç®—æ··åˆæ¯”ä¾‹
        base_level = int(current_difficulty)
        next_level = min(5, base_level + 1)
        decimal_part = current_difficulty - base_level
        
        prompt = f"""
        ä½ æ˜¯æ—¥æ–‡ N2 æ–¯å·´é”æ•™ç·´ã€‚
        
        ã€ç³»çµ±è³‡è¨Šã€‘
        é€™æ˜¯ç¬¬ {exec_count} æ¬¡ç‰¹è¨“ã€‚
        é€™æ˜¯é€£çºŒç¬¬ {streak_days} å¤©çš„æŒ‘æˆ° (Day {streak_days})ã€‚
        
        **ğŸ¯ ç›®æ¨™é›£åº¦ç­‰ç´šï¼š{current_difficulty:.1f}**
        é€™æ˜¯ä¸€å€‹æ··åˆé›£åº¦ï¼Œè«‹ä¾ç…§ä»¥ä¸‹æ¯”ä¾‹å‡ºé¡Œï¼š
        - **åŸºç¤é›£åº¦ (Lv{base_level})**ï¼š{difficulty_levels[base_level]} (ä½” {(1-decimal_part)*100:.0f}%)
        - **é€²éšé›£åº¦ (Lv{next_level})**ï¼š{difficulty_levels[next_level]} (ä½” {decimal_part*100:.0f}%)
        *(ä¾‹å¦‚é›£åº¦ 2.3ï¼Œä»£è¡¨å¤§éƒ¨åˆ†é¡Œç›®æ˜¯ Lv2ï¼Œä½†æ··å…¥ 30% çš„ Lv3 æŒ‘æˆ°é¡Œ)*
        
        ã€æƒ…ç·’èˆ‡é–‹å ´ã€‘
        {emotion_prompt}
        è«‹åœ¨é–‹å ´ç™½ä¸­æ˜ç¢ºæåˆ°ï¼šã€Œé€™æ˜¯æˆ‘å€‘çš„ç¬¬ {exec_count} æ¬¡ç‰¹è¨“ (Day {streak_days})ï¼ã€ã€‚
        
        ã€ä»Šæ—¥å–®å­—åº«ã€‘
        {word_list}
        
        è«‹è£½ä½œ **10 é¡Œ** ç¿»è­¯æ¸¬é©— (7é¡Œä¸­ç¿»æ—¥ï¼Œ3é¡Œæ—¥ç¿»ä¸­)ã€‚
        **é¡Œå‹è¦æ±‚ï¼šè«‹ç¶­æŒç°¡çŸ­ã€æ˜ç¢ºçš„å¥å­ã€‚è«‹åš´æ ¼éµå®ˆä¸Šè¿°çš„ã€Œæ··åˆé›£åº¦æ¯”ä¾‹ã€ï¼Œä¸è¦çªç„¶è®Šå¤ªé›£æˆ–å¤ªç°¡å–®ã€‚**
        
        ã€è¼¸å‡ºæ ¼å¼è¦æ±‚ (åš´æ ¼éµå®ˆ)ã€‘
        1. **èªè¨€**ï¼š
           - é–‹å ´ç™½ã€å–®å­—é ç¿’ã€é¡Œç›®èªªæ˜ï¼š**å…¨ç¨‹ä½¿ç”¨ç¹é«”ä¸­æ–‡**ã€‚
           - é¡Œç›®æœ¬èº«ï¼šæ—¥æ–‡æˆ–ä¸­æ–‡ã€‚
        
        2. **æ’ç‰ˆ**ï¼š
           - **åš´ç¦** ä½¿ç”¨ Markdown æ¨™é¡Œ (å¦‚ # æˆ– ##)ã€‚
           - è«‹ä½¿ç”¨ Emoji (å¦‚ âš”ï¸, ğŸ“š, ğŸ“, ğŸ”¹) ä¾†å€éš”æ®µè½èˆ‡é …ç›®ã€‚
           - **åš´ç¦** ä½¿ç”¨ HTML æ¨™ç±¤ (å¦‚ <br>)ï¼Œè«‹ç›´æ¥æ›è¡Œã€‚
        
        3. **çµæ§‹**ï¼š
           - Part 1: é¡Œç›®å· (å«é–‹å ´ã€å–®å­—ã€10é¡Œ)ã€‚**ä¸è¦**çµ¦ç­”æ¡ˆã€‚
           - åˆ†éš”ç·š: `|||SEPARATOR|||`
           - Part 2: è§£ç­”å· (å«åƒè€ƒç­”æ¡ˆèˆ‡è§£æ)ã€‚
        """
        
        try:
            response = model.generate_content(prompt, safety_settings=SAFETY_SETTINGS)
            if response.text and "|||SEPARATOR|||" in response.text:
                parts = response.text.split("|||SEPARATOR|||")
                send_telegram(parts[0].strip())
                user["pending_answers"] = parts[1].strip()
                
                user["stats"]["last_quiz_date"] = today_str
                user["stats"]["last_quiz_questions_count"] = 10
        except Exception as e:
            print(f"Error: {e}")
            send_telegram("âš ï¸ æ¸¬é©—ç”Ÿæˆå¤±æ•—")

    # ================= Scenario B: Bonus æ¨¡å¼ (èª˜æƒ‘é–‹å ´ + é›£åº¦éå¢) =================
    else:
        bonus_count = user["stats"]["bonus_answers_count"]
        # Bonus ä¹Ÿæ˜¯åŸºæ–¼æµ®é»æ•¸é›£åº¦å¾€ä¸ŠåŠ 
        base_diff = float(user["stats"].get("current_difficulty", 2.0))
        bonus_level_increase = (bonus_count // 3) * 0.5 + 0.5 # æ¯å¯«3é¡ŒåŠ  0.5 åˆ†é›£åº¦
        bonus_difficulty = min(5.0, base_diff + bonus_level_increase)
        
        print(f"ğŸ¤– ç”Ÿæˆ Bonus æŒ‘æˆ° (3é¡Œ) - åŸºç¤é›£åº¦:{base_diff:.1f} -> Bonusé›£åº¦:{bonus_difficulty:.1f}...")
        
        # è¨ˆç®—æ··åˆæ¯”ä¾‹ (Bonus)
        base_level = int(bonus_difficulty)
        next_level = min(5, base_level + 1)
        decimal_part = bonus_difficulty - base_level

        # ğŸ”¥ Bonus æç¤ºè©å„ªåŒ–ï¼šèª˜æƒ‘èªæ°£ + é«˜é›£åº¦è¨­å®š
        prompt = f"""
        ä½ æ˜¯æ—¥æ–‡ N2 æ–¯å·´é”æ•™ç·´ã€‚
        ä½¿ç”¨è€…ä»Šå¤©å·²ç¶“å®Œæˆæ¯æ—¥ä½œæ¥­ï¼Œä½†å¥¹**ä¸»å‹•**å†æ¬¡å›ä¾†åŸ·è¡Œç¨‹å¼ã€‚
        
        è«‹ç”¨ä¸€ç¨®**ã€Œå……æ»¿èª˜æƒ‘åŠ›èˆ‡æŒ‘æˆ°æ€§ã€**çš„èªæ°£é–‹å ´ã€‚
        ä¸è¦åªæ˜¯é©šè¨ï¼Œè€Œæ˜¯è¦åƒä¸€ä½é­”é¬¼æ•™ç·´çœ‹åˆ°å­¸å“¡ä¸»å‹•ç•™ä¸‹ä¾†åŠ ç·´æ™‚é‚£ç¨®ã€Œéœ²é½’ä¸€ç¬‘ã€çš„æ„Ÿè¦ºã€‚
        é€™æ˜¯ä¸€ç¨®å°å¼·è€…çš„èªå¯ï¼ŒåŒæ™‚å¸¶æœ‰æŒ‘é‡æ„å‘³ï¼šã€Œå–”ï¼Ÿé‚„ä¸æ»¿è¶³å—ï¼Ÿçœ‹ä¾†ä¸€èˆ¬çš„è¨“ç·´å·²ç¶“ç„¡æ³•æ»¿è¶³ä½ çš„é‡å¿ƒäº†...ğŸ˜ é‚£å°±ä¾†è©¦è©¦é€™å€‹å§ï¼ã€
        
        **ğŸ¯ Bonus é›£åº¦ç­‰ç´šï¼š{bonus_difficulty:.1f}**
        - **åŸºç¤é›£åº¦ (Lv{base_level})**ï¼š{difficulty_levels[base_level]} (ä½” {(1-decimal_part)*100:.0f}%)
        - **é€²éšé›£åº¦ (Lv{next_level})**ï¼š{difficulty_levels[next_level]} (ä½” {decimal_part*100:.0f}%)
        
        ä¸¦æä¾› **3 é¡Œ** ç¿»è­¯æŒ‘æˆ° (Bonus Challenge)ã€‚
        **é¡Œå‹è¦æ±‚ï¼š2 é¡Œä¸­ç¿»æ—¥ï¼Œ1 é¡Œæ—¥ç¿»ä¸­ã€‚**
        
        ã€ä»Šæ—¥å–®å­—åº«ã€‘
        {word_list}
        
        ã€è¼¸å‡ºæ ¼å¼è¦æ±‚ (åš´æ ¼éµå®ˆ)ã€‘
        1. **èªè¨€**ï¼š
           - é–‹å ´ç™½ã€é¡Œç›®èªªæ˜ï¼š**å…¨ç¨‹ä½¿ç”¨ç¹é«”ä¸­æ–‡**ã€‚
        
        2. **æ’ç‰ˆ**ï¼š
           - **åš´ç¦** ä½¿ç”¨ Markdown æ¨™é¡Œ (å¦‚ # æˆ– ##)ã€‚
           - è«‹ä½¿ç”¨ Emoji (å¦‚ ğŸ”¥, ğŸš€, ğŸ’¡, ğŸŒŸ) ä¾†å€éš”æ®µè½ã€‚
           - æ¨™é¡Œè«‹å¯«ï¼šâš”ï¸ **Bonus ç„¡é™æŒ‘æˆ° (Lv{bonus_difficulty:.1f})** âš”ï¸
           - **åš´ç¦** ä½¿ç”¨ HTML æ¨™ç±¤ (å¦‚ <br>)ï¼Œè«‹ç›´æ¥æ›è¡Œã€‚
        
        3. **çµæ§‹**ï¼š
           - Part 1: Bonus é¡Œç›®å· (å«é–‹å ´ã€3é¡Œ)ã€‚**ä¸è¦**çµ¦ç­”æ¡ˆã€‚
           - åˆ†éš”ç·š: `|||SEPARATOR|||`
           - Part 2: è§£ç­”å· (å«åƒè€ƒç­”æ¡ˆèˆ‡è§£æ)ã€‚
        """

        try:
            response = model.generate_content(prompt, safety_settings=SAFETY_SETTINGS)
            if response.text and "|||SEPARATOR|||" in response.text:
                parts = response.text.split("|||SEPARATOR|||")
                send_telegram(parts[0].strip())
                user["pending_answers"] = parts[1].strip() 
                
        except Exception as e:
            print(f"Error: {e}")
            send_telegram("âš ï¸ Bonus ç”Ÿæˆå¤±æ•—")

    return user

if __name__ == "__main__":
    v_data, u_data = process_data()
    u_data_updated = run_daily_quiz(v_data, u_data)
    
    save_json(VOCAB_FILE, v_data)
    if u_data_updated:
        save_json(USER_DATA_FILE, u_data_updated)
    else:
        save_json(USER_DATA_FILE, u_data)